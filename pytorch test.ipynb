{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my home-written modules\n",
    "import image_helpers\n",
    "import split_sets\n",
    "import pytorch_helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['savefig.dpi'] = 80*2\n",
    "plt.rcParams['figure.dpi'] = 80*2\n",
    "plt.rcParams['figure.figsize'] = np.array((10,6))*.5\n",
    "plt.rcParams['figure.facecolor'] = \"white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = image_helpers.data_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"matched_galaxies.csv\"))\n",
    "df = df.set_index(\"SpecObjID\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets\n",
    "df_Y = df[[\"MEDIAN\"]]\n",
    "df_Y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_Y.MEDIAN.values, bins=30)\n",
    "print(df_Y.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_with_images = glob.glob(os.path.join(data_dir, \n",
    "                                         \"images\",\n",
    "                                         \"processed\",\n",
    "                                         \"*.npy\"))\n",
    "ids_with_images = [os.path.split(filename)[1].replace(\".npy\", \"\")\n",
    "                   for filename in ids_with_images]\n",
    "ids_with_images = np.array(ids_with_images, dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a temporary directory of symlinks to images\n",
    "\n",
    "Remember, since these are symlinks, you probably can't have this within a Dropbox-tracked folder, since Dropbox will often convert symlinks into actual files, which would be a waste of space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_sets = split_sets.split_indices(ids_with_images)\n",
    "training_ids, validation_ids, testing_ids = id_sets\n",
    "\n",
    "df_Y[\"target\"] = df_Y[\"MEDIAN\"] - df_Y.loc[training_ids].MEDIAN.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"temp_directory: \", pytorch_helpers.temp_directory)\n",
    "\n",
    "pytorch_helpers.create_pytorch_directory_structure(\n",
    "    ids_with_images,\n",
    "    training_ids, validation_ids, testing_ids,\n",
    "    start_from_scratch=False,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = pytorch_helpers.create_data_loaders(\n",
    "    df_Y,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.hstack([z_tensor \n",
    "                    for _, z_tensor in data_loaders[\"training\"]\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_helpers.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pytorch_helpers.Model(data_loaders, \n",
    "                              continue_training=False)\n",
    "model = model.to(model.device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "optimizer.param_groups[0][\"initial_lr\"] = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "# Evolve LR using cosine annealing\n",
    "# note: in order to setup the restarts, I should read: https://arxiv.org/abs/1608.03983\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                           T_max = 10, # currently in units of epochs\n",
    "                                           last_epoch=model.epoch_counter,\n",
    "                                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 12\n",
    "num_epochs = 3\n",
    "\n",
    "torch.set_num_threads(num_threads)\n",
    "\n",
    "model = model.train_model(criterion, optimizer, scheduler,\n",
    "                          num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, outputs = model.apply(\"validation\")\n",
    "print(targets.shape)\n",
    "\n",
    "plt.hist2d(targets, outputs, bins=30, cmap=\"Greys\")\n",
    "plt.plot(*([-1, 1],)*2, color=\"black\")\n",
    "plt.axvline(0, linestyle=\"dashed\", color=\"black\")\n",
    "plt.axhline(0, linestyle=\"dashed\", color=\"black\")\n",
    "\n",
    "print(\"RMS error: \", np.mean((targets - outputs)**2)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(model.filename_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.loss**.5, label=\"training\")\n",
    "plt.plot(df.val_loss**.5, label=\"validation\")\n",
    "\n",
    "plt.axhline(df_Y.MEDIAN.std(), \n",
    "            linestyle=\"dashed\", color=\"black\",\n",
    "            label=\"std.dev.\",\n",
    "           )\n",
    "\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"RMS Error (dex)\")\n",
    "\n",
    "ylim = plt.ylim()\n",
    "\n",
    "plt.ylim(top=min(1, max(ylim)))\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
