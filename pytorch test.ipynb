{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import types\n",
    "\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my home-written modules\n",
    "import image_helpers\n",
    "import split_sets\n",
    "# import model_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['savefig.dpi'] = 80*2\n",
    "plt.rcParams['figure.dpi'] = 80*2\n",
    "plt.rcParams['figure.figsize'] = np.array((10,6))*.5\n",
    "plt.rcParams['figure.facecolor'] = \"white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = image_helpers.data_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, \"matched_galaxies.csv\"))\n",
    "df = df.set_index(\"SpecObjID\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets\n",
    "df_Y = df[[\"MEDIAN\"]]\n",
    "df_Y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_Y.MEDIAN.values, bins=30)\n",
    "print(df_Y.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_with_images = glob.glob(os.path.join(data_dir, \n",
    "                                         \"images\",\n",
    "                                         \"processed\",\n",
    "                                         \"*.npy\"))\n",
    "ids_with_images = [os.path.split(filename)[1].replace(\".npy\", \"\")\n",
    "                   for filename in ids_with_images]\n",
    "ids_with_images = np.array(ids_with_images, dtype=int)\n",
    "\n",
    "ids_with_images_full = ids_with_images.copy()\n",
    "# ids_with_images = ids_with_images[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a temporary directory of symlinks to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_sets = split_sets.split_indices(ids_with_images, \n",
    "                                  )\n",
    "training_ids, validation_ids, testing_ids = id_sets\n",
    "\n",
    "df_Y[\"target\"] = df_Y[\"MEDIAN\"] - df_Y.loc[training_ids].MEDIAN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from_scratch=True\n",
    "\n",
    "temp_directory = \"/Users/egentry/tmp_pytorch/\"\n",
    "\n",
    "if start_from_scratch:\n",
    "    shutil.rmtree(temp_directory)\n",
    "\n",
    "if not os.path.isdir(temp_directory):\n",
    "    os.makedirs(temp_directory)\n",
    "    \n",
    "source_format = os.path.join(\n",
    "    os.getcwd(),\n",
    "    data_dir, \n",
    "    \"images\",\n",
    "    \"processed\",\n",
    "    \"{galaxy_id}.npy\")\n",
    "\n",
    "target_dir_format = os.path.join(temp_directory, \"{val_train}\", \"{galaxy_id}\")\n",
    "target_format = os.path.join(target_dir_format, \"{galaxy_id}.npy\")\n",
    "\n",
    "def get_val_train(galaxy_id):\n",
    "    if galaxy_id in training_ids:\n",
    "        return \"training\"\n",
    "    \n",
    "    if galaxy_id in validation_ids:\n",
    "        return \"validation\"\n",
    "    \n",
    "    if galaxy_id in testing_ids:\n",
    "        return \"testing\"\n",
    "    \n",
    "\n",
    "for i, galaxy_id in enumerate(ids_with_images):\n",
    "    val_train = get_val_train(galaxy_id)\n",
    "    \n",
    "    target_dir = target_dir_format.format(galaxy_id=galaxy_id, val_train=val_train)\n",
    "    if not os.path.isdir(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    \n",
    "    target_filename = target_format.format(galaxy_id=galaxy_id, val_train=val_train)\n",
    "    try:\n",
    "        os.symlink(\n",
    "            source_format.format(galaxy_id=galaxy_id),    \n",
    "            target_filename,\n",
    "        )\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    if i > 1000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "I should just use `torchvision.datasets.DatasetFolder` and create a directory with the structure `torch_data/<galaxy_id>/<galaxy_id>.npy`, with a loader that reads in the path, and then transforms the label \"`galaxy_id`\" using `df.loc`. I shouldn't actually copy the image files; I should just symlink (**BUT I NEED TO DO THIS OUTSIDE DROPBOX**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "#         transforms.RandomResizedCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(), # requires a PIL-able image\n",
    "#         transforms.RandomVerticalFlip(), # requires a PIL-able image\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(), # requires a PIL-able image\n",
    "#         transforms.RandomVerticalFlip(), # requires a PIL-able image\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(path):\n",
    "    img =  np.load(path)\n",
    "    img = img[:3]\n",
    "    if np.random.choice((True, False)):\n",
    "        img = img[:,:,::-1]\n",
    "        img = np.array(img)\n",
    "    if np.random.choice((True, False)):\n",
    "        img = img[:,::-1,:]\n",
    "        img = np.array(img)\n",
    "    \n",
    "    img = img.transpose((1, 2, 0)) # annoying, but pytorch is going to rotate it back\n",
    "    return img\n",
    "\n",
    "def target_transform(target):\n",
    "    \"\"\"transforms `target` from a galaxy_id to the metallicity (regression target)\"\"\"\n",
    "    target = int(target)\n",
    "    return df_Y.loc[galaxy_id].target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = [\"npy\"]\n",
    "\n",
    "image_datasets = {x: datasets.DatasetFolder(os.path.join(temp_directory, x),\n",
    "                                            loader,\n",
    "                                            extensions,\n",
    "                                            data_transforms[x],\n",
    "                                            target_transform=target_transform)\n",
    "                  for x in ['training', 'validation']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['training', 'validation']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['training', 'validation']}\n",
    "image_datasets['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = image_datasets['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, \n",
    "                num_epochs=10,\n",
    "                verbose=False\n",
    "               ):\n",
    "    \"\"\"\n",
    "    model: the full pytorch model\n",
    "    criterion: the loss function; callable(prediction, targets)\n",
    "    optimizer: pytorch optimizer object\n",
    "    scheduler: LR scheduler (see `torch.optim.lr_scheduler`)\n",
    "    \n",
    "    I guess optimizer already needs to be linked to criterion?\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['training', 'validation']:\n",
    "            if phase == 'training':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.reshape((-1, 1))\n",
    "                targets = targets.to(device=device, dtype=torch.float)\n",
    "                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'training'):\n",
    "                    outputs = model(inputs)\n",
    "                    if verbose: print(\"outputs shape: \", outputs.shape)\n",
    "                    loss = criterion(outputs, targets)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'training':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            print('{} loss: {:.4f}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'validation' and best_loss > epoch_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet34(pretrained=True)\n",
    "\n",
    "def forward(self, x, verbose=False):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.maxpool(x)\n",
    "\n",
    "    x = self.layer1(x)\n",
    "    if verbose: print(\"after layer 1: \", x.shape)\n",
    "\n",
    "    x = self.layer2(x)\n",
    "    if verbose: print(\"after layer 2: \", x.shape)\n",
    "\n",
    "    x = self.layer3(x)\n",
    "    if verbose: print(\"after layer 3: \", x.shape)\n",
    "\n",
    "    x = self.layer4(x)\n",
    "    if verbose: print(\"after layer 4: \", x.shape)\n",
    "\n",
    "    x = self.avgpool(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.fc(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "model_ft.forward = types.MethodType(forward, model_ft)\n",
    "\n",
    "model_ft.avgpool = nn.AdaptiveAvgPool2d((1,1), )\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 1, )\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters())\n",
    "\n",
    "# Evolve LR using cosine annealing\n",
    "# note: in order to setup the restarts, I should read: https://arxiv.org/abs/1608.03983\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, \n",
    "                                           T_max = 20, # in units of epochs\n",
    "                                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(6)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, scheduler,\n",
    "                       num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
